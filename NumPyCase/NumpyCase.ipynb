{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0a3612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from time import perf_counter\n",
    "\n",
    "#Generate synthetic data: a numerical matrix of at least 1000×5 dimensions\n",
    "rng = np.random.default_rng(42) #the same matrix comes out \n",
    "data = rng.normal(0,1,(1000,5))\n",
    "print (data)\n",
    "\n",
    "#Normalization\n",
    "#normalized_dataset = np.array(data)\n",
    "\n",
    "max_value = data.max()\n",
    "min_value = data.min()\n",
    "normalized_dataset = (data-min_value)/(max_value-min_value)\n",
    "print(normalized_dataset.min(), normalized_dataset.max())\n",
    "\n",
    "#Thresholding\n",
    "boolean_mask = data.mean()\n",
    "thresholding_dataset = data>boolean_mask\n",
    "# print(boolean_mask)\n",
    "print(thresholding_dataset)\n",
    "\n",
    "#Categorical Encoding\n",
    "bins = [-np.inf, 0, 1, np.inf]  # -∞ - 0, 0-1, 1 +  constraints.\n",
    "labels = [0, 1, 2]\n",
    "\n",
    "categorical_dataset = np.digitize(data,bins) -1\n",
    "print(categorical_dataset)\n",
    "\n",
    "# categ_dataset = np.digitize(data,bins) # bu sekilde aralik 1,2,3 döndürüyor ancak -1 ekleyince 0,1,2 oluyor.\n",
    "# print(categ_dataset)\n",
    "\n",
    "# region ---Arrays---\n",
    "\n",
    "s = np.array([1,2,3,4,5])\n",
    "k = np.array([[[5,10,15],[3,6,9],[2,4,6]]])\n",
    "\n",
    "print(\"s\", s, \"ndim:\", s.ndim, \"shape:\", s.shape, \"dtype:\", s.dtype) #shape: (5,): 1 boyutlu\n",
    "print(\"k\",k, \"ndim:\", k.ndim, \"shape:\" , k.shape, \"dtype:\" , k.dtype) #shape: (1, 3, 3): 1 tane 3x3 matris\n",
    "\n",
    "a = np.arange(0,5,2) #independet part arange only depends on its (start, stop, step) values, it doesn’t use other arrays such as s,k.\n",
    "b = np.linspace(0,2,6)\n",
    "z = np.zeros((3,3))\n",
    "o = np.ones((4,3))\n",
    "i = np.eye(2,2)\n",
    "print(a,\"\\n\", b, \"\\n\",z, \"\\n\", o, \"\\n\", i)\n",
    "#endregion\n",
    "\n",
    "# region----TRANSACTIONS----\n",
    "#Boolen Indexleme\n",
    "#1.\n",
    "zd = np.array([[3,4],[2,3]])#2D\n",
    "dd = np.array([[[3,2],[1,4],[2,5]]])#3D\n",
    "print(zd[zd%2 == 0])\n",
    "print(dd[dd%3 == 0])\n",
    "#2.\n",
    "rng_a = np.random.default_rng(42) #the same matrix comes out \n",
    "e = rng_a.uniform(0,30,(2,3)) #0-30 random numbers.  rng.integers: integer 2 Ndim\n",
    "print(e)\n",
    "print(e[e%2 != 0])\n",
    "\n",
    "rng_b = np.random.default_rng(42) #the same matrix comes out \n",
    "g = rng_b.uniform(0,30,(2,1,3)) #3D\n",
    "print(g)\n",
    "print(g[g%2 != 0])\n",
    "##As Ahmet Hoca did\n",
    "bi = np.arange(1,13).reshape(3,4) #2D\n",
    "print(bi[bi%2 == 0])\n",
    "\n",
    "di = np.arange(1,13).reshape(3,1,4) #3D\n",
    "print(di)\n",
    "print(di[di%3==0])\n",
    "\n",
    "#Slicing\n",
    "sz = np.arange(1,21).reshape(4,5)  #2D\n",
    "print(sz)\n",
    "print(sz[0,0]) #first element\n",
    "print(sz[:,1]) #all rows 2. columns \n",
    "print(sz[1,:2]) #2. row 0 and 1.,2. columns\n",
    "print(sz.T) # transpoz\n",
    "print(sz[1:3, 3:6]) #1.,2. rows and 4.,5. columns \n",
    "\n",
    "sd = np.arange(1,21).reshape(2,2,5) #3D\n",
    "print(sd)\n",
    "print(sd[0]) #the entire first block\n",
    "print(sd[:,:,2]) #all rows 3. columns index olarak\n",
    "print(sd[1,1,:]) #2. block, 2. rows\n",
    "\n",
    "\n",
    "# Fency Indexleme\n",
    "# arr = np.array([10,20,30,40,50])\n",
    "# idx = [0,2,4]\n",
    "# print(zd[idx])\n",
    "#endregion\n",
    "\n",
    "# region Brodcasting\n",
    "#NumPy şekilleri (shape) sağdan hizalar. \n",
    "# Eğer sütun sayısı eşitse → satırlara yayılır (satır-bazlı)\n",
    "# Eğer satır sayısı eşitse → sütunlara yayılır (sütun-bazlı)\n",
    "\n",
    "# A = np.ones((3,4))\n",
    "# b = np.array([1,2,3,4])\n",
    "# print(A+b)\n",
    "\n",
    "#Brodcasting with Multi-Dimensional Arrays (column-wise)\n",
    "# array1 = np.array([[1, 2, 3], [4, 5, 6]])   # shape = (2,3)\n",
    "# array2 = np.array([[10], [20]]) # shape = (2,1) 2 rows 1 column\n",
    "# result = array1 + array2\n",
    "# print(result)\n",
    "\n",
    "#Broadcasting with Different Dimensions (row-wise)\n",
    "bc_a = np.array([[1, 2, 3], [4, 5, 6]]) #shape = (2,3) 2 rows 3 columns\n",
    "bc_b = np.array([10, 20, 30])  # shape = (3,) 1 row 3 columns\n",
    "result = bc_a + bc_b\n",
    "print(result)\n",
    "\n",
    "# Row-based z-normalization (Bu bölümde her satır, kendi ortalama ve standart sapmasına göre standardize edilmiştir.)\n",
    "# Amaç: satır ortalamalarını ~0, satır std'lerini ~1 yapmak.\n",
    "row_mean = bc_a.mean(axis=1, keepdims=True)  #tek satırlık bir vektör, normalizasyon için kullanılmaz.\n",
    "row_std = bc_a.std(axis=1, keepdims=True) \n",
    "row_std_safe = np.where(row_std == 0, 1, row_std)\n",
    "Z = (bc_a - row_mean) / row_std_safe\n",
    "print(Z)\n",
    "\n",
    "print(\"Original Data:\\n\",bc_a)\n",
    "print(\"Global Mean:\", bc_a.mean())\n",
    "print(\"Global Std:\", bc_a.std())\n",
    "\n",
    "print(\"Row Mean:\\n\" , row_mean)\n",
    "print(\"Row Std:\\n\" , row_std)\n",
    "print(\"Row Safe Std:\\n\" , row_std_safe)\n",
    "\n",
    "print(\"Normalized Result:\\n\", Z)\n",
    "print(\"Row means after normalization:\\n\", Z.mean(axis=1))\n",
    "print(\"Row stds after normalization:\\n\", Z.std(axis=1))\n",
    "\n",
    "summary = np.column_stack([\n",
    "    row_mean.ravel(), \n",
    "    row_std.ravel(), \n",
    "    Z.mean(axis=1), \n",
    "    Z.std(axis=1)])\n",
    "print(\"Rows: [Bef_Means, Bef_Stds, Aft_Means, Aft_Stds]\\n\", summary)\n",
    "# print(\"Rows: [Bef.N. Means, Bef.N. Stds, Aft. N. Means, Aft.N. Stds]\\n\", np.round(summary,6))\n",
    "\n",
    "## Önce / Sonra Karşılaştırma \n",
    "#Normalizasyon öncesinde satır ortalamaları ve standart sapmaları farklıydı (bkz. “Row means/stds (before)”). \n",
    "#Broadcasting ile satır bazlı z-normalizasyon uygulandı: her satırdan kendi ortalaması çıkarılıp kendi std’sine bölündü. \n",
    "#İşlem sonrası her satırın ortalaması ≈ 0 ve std’si ≈ 1 oldu (bkz. “Row means/stds (after)” ve otomatik doğrulama). \n",
    "#Böylece tüm satırlar aynı ölçekte karşılaştırılabilir hale geldi.\n",
    "#endregion\n",
    "\n",
    "#Data Cleaning\n",
    "print(\"DATA CLEANING\")\n",
    "nmb_nan = 5 #number of nan I want to add\n",
    "index_b = np.random.choice(data.size, nmb_nan, replace=False) # choosing random indexes to put NaN\n",
    "# index_b = rng.choice(data.size, nmb_nan, replace=False) # choosing random indexes to put NaN\n",
    "data.ravel()[index_b] = np.nan # adding nan to the data.\n",
    "print(data)\n",
    "\n",
    "#Checking for NaN \n",
    "nan_val= (np.isnan(data).sum())\n",
    "print(\"NaN Values: \\n \" , nan_val)\n",
    "\n",
    "#Imputation\n",
    "# Ortalama ve medyan sütun bazlı\n",
    "col_means = np.nanmean(data, axis=0) #nan lari göz ardi ederek \n",
    "print(\"Column means:\", col_means)\n",
    "# col_medians = np.nanmedian(data, axis=0) #medyan bazli doldurmak isteseydim\n",
    "# print(\"Column medians:\", col_medians)\n",
    "fll =  np.where(np.isnan(data))   # NaN olan indexleri bul\n",
    "print(\"Nan Indexes:\\n\", fll)\n",
    "data[fll] = np.take(col_means, fll[1]) #ortalama ile doldur.\n",
    "print(\"After mean imputation:\\n\", data)\n",
    "\n",
    "# region Outliers\n",
    "#np.clip Method\n",
    "#Defining the outliers\n",
    "#1. calculate std and mean\n",
    "clm_mean = data.mean(axis=0)  #\n",
    "clm_std = data.std(axis=0) \n",
    "print(\"Column Mean: \\n\", clm_mean)\n",
    "print(\"Column Std: \\n\", clm_std)\n",
    "#2. Alt ve üst sınırları belirle (mean ± 3*std)\n",
    "lwr_value = clm_mean - 3*clm_std\n",
    "upp_value = clm_mean + 3*clm_std\n",
    "print(\"Lower limits:\", lwr_value)\n",
    "print(\"Upper limits:\", upp_value)\n",
    "#3. Outlier clipping uygula\n",
    "data_clipped = np.clip(data,lwr_value,upp_value)\n",
    "print(\"After clipping: \\n\", data_clipped)\n",
    "\n",
    "# Outlier adayları (clipping öncesi)\n",
    "mask = (data < lwr_value) | (data > upp_value)   # 3σ dışı olanlar\n",
    "print(\"Clipped count:\", mask.sum()) #teorik olarak değişmesi beklenenler.\n",
    "print(\"Clipped positions (first 10):\", np.argwhere(mask)[:10]) #np.argwhere(mask) returns the coordinates (row, column) of the cells that are True.\n",
    "\n",
    "#Gerçekten değişen hücreler (clipping sonrası)\n",
    "diff_idx = np.argwhere(data != data_clipped)\n",
    "print(\"Changed cells:\", diff_idx.shape[0]) #.shape--> boyutlari (Satir,sütun sayisini) döner. .shape[0] = satır sayısı.\n",
    "\n",
    "#Hangi hücreler, önce/sonra ne oldu?\n",
    "outliers = np.argwhere(mask)[:10]\n",
    "for i, j in outliers:\n",
    "   print(f\"Row {i}, Col {j} | Before: {data[i, j]}  -> After: {data_clipped[i, j]}\")\n",
    "#endregion\n",
    "\n",
    "# region Outliers deneme\n",
    "bc_s = np.array([[1, 2, 3], [4, 5, 6]], dtype=float) #np.nan float alir o yüzden cevirdik.\n",
    "nmb_nb = 2  #number of nan I want to add\n",
    "index_s = np.random.choice(bc_s.size, nmb_nb, replace=False) # choosing random indexes to put NaN\n",
    "bc_s.ravel()[index_s] = np.nan # adding nan to the data.\n",
    "print(\"NaN injected Dataset: \\n\", bc_s)\n",
    "\n",
    "# #Checking for NaN \n",
    "nan_vals= (np.isnan(bc_s).sum())\n",
    "print(\"NaN Values: \\n\", nan_vals)\n",
    "\n",
    "# #Imputation\n",
    "# #Ortalama sütun bazlı\n",
    "means_bc_s =  np.nanmean(bc_s, axis=0)\n",
    "print(\"Column means:\", means_bc_s)\n",
    "flls =  np.where(np.isnan(bc_s))   # NaN olan indexleri bul\n",
    "print(\"Nan Indexes: \\n\", flls)\n",
    "\n",
    "bc_s[flls] = np.take(means_bc_s, flls[1]) #ortalama ile doldur.\n",
    "print(\"Trial Dataset After mean imputation:\\n\", bc_s)\n",
    "\n",
    "# #Outliers\n",
    "# clm_mean = bc_s.mean(axis=0)  #\n",
    "clm_std = bc_s.std(axis=0) \n",
    "#Alt ve üst sınırları belirle (mean ± 3*std)\n",
    "lwr_value = clm_mean - 3*clm_std\n",
    "upp_value = clm_mean + 3*clm_std\n",
    "print(\"Lower limits:\", lwr_value)\n",
    "print(\"Upper limits:\", upp_value)\n",
    "#Outlier clipping uygula\n",
    "bc_s_clipped = np.clip(bc_s,lwr_value,upp_value)\n",
    "print(\"After clipping: \\n\", bc_s_clipped)\n",
    "#endregion\n",
    "\n",
    "# region Physics (Linear Algebra) \n",
    "\n",
    "np.random.seed(42)   # reproducible\n",
    "n = 3\n",
    "A = np.random.rand(n, n)  # 3x3 rastgele matris\n",
    "b = np.random.rand(n)     # 3 boyutlu vektör\n",
    "\n",
    "print(\"Matrix A:\\n\", A)\n",
    "print(\"Vector b:\\n\", b)\n",
    "#Solution\n",
    "x = np.linalg.solve(A,b)\n",
    "print(\"Solution:\", x)\n",
    "#Check\n",
    "print(\"Check A@x:\", A @ x)\n",
    "print(\"Should equal b:\", b)\n",
    "\n",
    "cond_num = np.linalg.cond(A) #The condition number measures the numerical stability of the matrix A. \n",
    "print(\"Condition number:\", cond_num)\n",
    "\n",
    "# Objective: The aim was to solve the linear system A · x = b using  a randomly generated square matrix A and vector b.\n",
    "# Method: The system was solved using the np.linalg.solve function, and the condition number of the matrix was computed.\n",
    "\n",
    "# Result: The solution vector x was successfully obtained. \n",
    "# The condition number was calculated as approximately 65.97.\n",
    "\n",
    "# Comment: This value indicates that the system is moderately conditioned. \n",
    "# Small changes in the input data may be amplified up to about 66 times in the solution. \n",
    "# However, since the value is not excessively high, the solution can be considered \n",
    "# generally reliable and usable.\n",
    "\n",
    "#endregion \n",
    "\n",
    "# region Performance\n",
    "print(\"PERFORMANCE\")\n",
    "#NumPy (vektorize)  \n",
    "# rng = np.random.default_rng(42) #the same matrix comes out \n",
    "data = rng.normal(0,1,(1000,5)).astype(float)\n",
    "nan_count = 5 #number of nan I want to add\n",
    "# 1. NaN ekle\n",
    "nan_idx = rng.choice(data.size, nan_count, replace=False)\n",
    "data.ravel()[nan_idx] = np.nan  \n",
    "# 2. Sütun ortalamalarını hesapla\n",
    "col_means = np.nanmean(data, axis=0)\n",
    "# 3. NaN indexlerini bul\n",
    "fll_prf = np.where(np.isnan(data))\n",
    "\n",
    "def vectorized_imputation(data, fll_prf, col_means):\n",
    "    vect_imp = data.copy()\n",
    "    start_vec = perf_counter()\n",
    "    # 4. NaN olan yerlere sütun ortalamasını yaz\n",
    "    data[fll_prf] = np.take(col_means, fll_prf[1])\n",
    "    end_vec = perf_counter()\n",
    "    return data, end_vec - start_vec\n",
    "result, vec_time = vectorized_imputation(data, fll_prf, col_means)\n",
    "print(\"Vectorization time:\\n\", vec_time)\n",
    "\n",
    "#Python for loop\n",
    "#Preperation kismi ayni\n",
    "#Adil ölçüm için: dolduracağımız ayrı bir kopya\n",
    "data_loop = data.copy()\n",
    "start_loop = perf_counter()\n",
    "for i, j in zip(fll_prf[0], fll_prf[1]): #fll_prf[0] = NaN’lerin satırları, fll_prf[1] = NaN’lerin sütunları: zip(...) = bu satır ve sütunları koordinat çiftlerine dönüştürür\n",
    "    data_loop[i, j] = col_means[j]  #j’nci sütunun ortalaması, NaN’leri sütun ortalamasıyla dolduruyorum\n",
    "end_loop = perf_counter()\n",
    "print(\"For Loop time:\\n\", end_loop - start_loop)\n",
    "# endregion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1259baf3",
   "metadata": {},
   "source": [
    "# Bu çalışmada her satır, kendi ortalaması ve standart sapmasına göre z-normalizasyon işlemine tabi tutulmuştur. \n",
    "# Amaç, her satırın ortalamasını yaklaşık 0’a, standart sapmasını ise yaklaşık 1’e indirgemektir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1090a6",
   "metadata": {},
   "source": [
    "## Önce / Sonra Karşılaştırma \n",
    "# Normalizasyon öncesinde satır ortalamaları ve standart sapmaları farklıydı (Bef_Means/Stds). \n",
    "# Broadcasting ile satır bazlı z-normalizasyon uygulandı: her satırdan kendi ortalaması çıkarılıp kendi std’sine bölündü. \n",
    "# İşlem sonrası her satırın ortalaması ≈ 0 ve std’si ≈ 1 oldu (Aft_Means/Stds). \n",
    "# Böylece tüm satırlar aynı ölçekte karşılaştırılabilir hale geldi."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
